{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfffdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok: /home/mlic/kawon/251222_metaworld/metaworld-algorithms/metaworld_algorithms/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "import orbax.checkpoint as ocp\n",
    "import sys\n",
    "\n",
    "\n",
    "REPO_ROOT = Path(\"/home/mlic/kawon/251222_metaworld/metaworld-algorithms\")\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "import metaworld_algorithms\n",
    "print(\"ok:\", metaworld_algorithms.__file__)\n",
    "from metaworld_algorithms.checkpoint import get_agent_checkpoint_restore_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd26a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_ROOT = Path(\n",
    "    \"/home/mlic/kawon/251222_metaworld/metaworld-algorithms/\"\n",
    "\n",
    "    \"examples/multi_task/run_results9/mt10_custom_mtsac_1/checkpoints\"\n",
    ")\n",
    "\n",
    "STEP = 1599990   # 네가 보고 싶은 step\n",
    "agent_dir = CKPT_ROOT / str(STEP) / \"agent\"\n",
    "SEED = 1\n",
    "\n",
    "# MT10 Task List\n",
    "MT10_TASKS = [\n",
    "    \"reach-v2\", \"push-v2\", \"pick-place-v2\", \"door-open-v2\", \"drawer-open-v2\", \"drawer-close-v2\",\n",
    "    \"button-press-topdown-v2\", \"peg-insert-side-v2\", \"window-open-v2\", \"window-close-v2\"\n",
    "]\n",
    "TARGET_TASK_IDX = 9\n",
    "assert (CKPT_ROOT / str(STEP)).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ab557ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaworld_algorithms.envs import MetaworldConfig\n",
    "\n",
    "env_config = MetaworldConfig(\n",
    "    env_id=\"MT10\",\n",
    "    use_one_hot=True,\n",
    "    terminate_on_success=False,\n",
    "    max_episode_steps=200,\n",
    "    reward_func_version=\"v2\",\n",
    "    num_goals=50,\n",
    "    reward_normalization_method=None,\n",
    "    normalize_observations=False,\n",
    "    # render_mode 제거\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "325e5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 envs. Obs shape: (10, 49)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# 10개의 환경을 동시 생성 (MT10의 모든 태스크 커버 가능)\n",
    "envs = gym.make_vec(\n",
    "    f\"Meta-World/{env_config.env_id}\",\n",
    "    num_envs=10,  # <--- ✅ 10개 생성!\n",
    "    seed=SEED,\n",
    "    # env_config 값들 전달\n",
    "    use_one_hot=env_config.use_one_hot,\n",
    "    terminate_on_success=env_config.terminate_on_success,\n",
    "    max_episode_steps=env_config.max_episode_steps,\n",
    "    vector_strategy=\"async\",\n",
    "    reward_function_version=env_config.reward_func_version,\n",
    "    num_goals=env_config.num_goals,\n",
    "    reward_normalization_method=env_config.reward_normalization_method,\n",
    "    normalize_observations=env_config.normalize_observations,\n",
    "    render_mode=\"rgb_array\", \n",
    ")\n",
    "\n",
    "obs, _ = envs.reset()\n",
    "print(f\"Created {envs.num_envs} envs. Obs shape: {obs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12460104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaworld_algorithms.rl.algorithms.mtsac import MTSAC, MTSACConfig\n",
    "from metaworld_algorithms.config.networks import ContinuousActionPolicyConfig, QValueFunctionConfig\n",
    "from metaworld_algorithms.config.nn import VanillaNetworkConfig\n",
    "from metaworld_algorithms.config.optim import OptimizerConfig\n",
    "\n",
    "algo_config = MTSACConfig(\n",
    "    num_tasks=10,\n",
    "    gamma=0.99,\n",
    "\n",
    "    actor_config=ContinuousActionPolicyConfig(\n",
    "        network_config=VanillaNetworkConfig(\n",
    "            optimizer=OptimizerConfig(max_grad_norm=1.0)\n",
    "        )\n",
    "    ),\n",
    "    critic_config=QValueFunctionConfig(\n",
    "        network_config=VanillaNetworkConfig(\n",
    "            optimizer=OptimizerConfig(max_grad_norm=1.0),\n",
    "        )\n",
    "    ),\n",
    "    num_critics=2,\n",
    "\n",
    "    use_inter_task_sampling=True,\n",
    "    use_intra_task_sampling=True,\n",
    "\n",
    "    use_success_based_il=True,\n",
    "    success_ema_tau=0.01,\n",
    "    il_weight_mode=\"sigmoid\",\n",
    "    il_weight_temp=0.1,\n",
    "    il_weight_power=2.0,\n",
    "    il_loss_type=\"mse\",\n",
    "    il_coef=1.0,\n",
    "\n",
    "    # 안전빵(디폴트가 같아도 명시 추천)\n",
    "    il_qfilter_top_p=0.2,\n",
    "    il_qfilter_min_good=8,\n",
    ")\n",
    "\n",
    "agent = MTSAC.initialize(algo_config, env_config, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab6ed08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent restored from: /home/mlic/kawon/251222_metaworld/metaworld-algorithms/examples/multi_task/run_results9/mt10_custom_mtsac_1/checkpoints/199990/agent\n"
     ]
    }
   ],
   "source": [
    "from orbax.checkpoint import checkpoint_utils\n",
    "\n",
    "agent_ckptr = ocp.PyTreeCheckpointer()\n",
    "# Construct restore_args ensuring mesh/sharding is set to current available device (e.g. CPU)\n",
    "restore_args = checkpoint_utils.construct_restore_args(agent)\n",
    "agent = agent_ckptr.restore(str(agent_dir), item=agent, restore_args=restore_args)\n",
    "\n",
    "print(\"agent restored from:\", agent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed9033e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent restored from: /home/mlic/kawon/251222_metaworld/metaworld-algorithms/examples/multi_task/run_results9/mt10_custom_mtsac_1/checkpoints/199990/agent\n"
     ]
    }
   ],
   "source": [
    "CKPT_ROOT = Path(\n",
    "    \"/home/mlic/kawon/251222_metaworld/metaworld-algorithms/\"\n",
    "    \"examples/multi_task/run_results9/mt10_custom_mtsac_1/checkpoints\"\n",
    ")\n",
    "step_dir = CKPT_ROOT / str(STEP)\n",
    "agent_dir = step_dir / \"agent\"  # 경로 정의 복구\n",
    "\n",
    "# Checkpoint restoration with fix\n",
    "from orbax.checkpoint import checkpoint_utils\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "agent_ckptr = ocp.PyTreeCheckpointer()\n",
    "\n",
    "# Construct restore_args ensuring mesh/sharding is set to current available device (e.g. CPU)\n",
    "# This prevents the \"sharding passed to deserialization should be specified\" error\n",
    "restore_args = checkpoint_utils.construct_restore_args(agent)\n",
    "\n",
    "agent = agent_ckptr.restore(str(agent_dir), item=agent, restore_args=restore_args)\n",
    "\n",
    "print(\"agent restored from:\", agent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a42f596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rollout...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Render\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# AsyncVectorEnv 대응: call(\"render\")로 모든 환경의 렌더링 결과를 리스트로 받음\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     frames_list = \u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrender\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# 첫 번째 환경(0번)의 영상만 저장\u001b[39;00m\n\u001b[32m     23\u001b[39m     frames.append(frames_list[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/site-packages/gymnasium/vector/async_vector_env.py:489\u001b[39m, in \u001b[36mAsyncVectorEnv.call\u001b[39m\u001b[34m(self, name, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call a method from each parallel environment with args and kwargs.\u001b[39;00m\n\u001b[32m    479\u001b[39m \n\u001b[32m    480\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m \u001b[33;03m    List of the results of the individual calls to the method or property for each environment.\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m.call_async(name, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/site-packages/gymnasium/vector/async_vector_env.py:545\u001b[39m, in \u001b[36mAsyncVectorEnv.call_wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28mself\u001b[39m._state = AsyncState.DEFAULT\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m multiprocessing.TimeoutError(\n\u001b[32m    542\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe call to `call_wait` has timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m second(s).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m results, successes = \u001b[38;5;28mzip\u001b[39m(*[\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_pipes])\n\u001b[32m    546\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_if_errors(successes)\n\u001b[32m    547\u001b[39m \u001b[38;5;28mself\u001b[39m._state = AsyncState.DEFAULT\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/multiprocessing/connection.py:250\u001b[39m, in \u001b[36m_ConnectionBase.recv\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(buf.getbuffer())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Rollout and Render\n",
    "import imageio\n",
    "import numpy as np\n",
    "import jax\n",
    "os.environ[\"EGL_LOG_LEVEL\"] = \"fatal\"\n",
    "\n",
    "frames = []\n",
    "obs, info = envs.reset()\n",
    "print(\"Starting rollout...\")\n",
    "\n",
    "for i in range(200):  # max_episode_steps\n",
    "    # Deterministic action selection\n",
    "    action = agent.eval_action(obs)\n",
    "    \n",
    "    # Environment step\n",
    "    obs, reward, terminated, truncated, info = envs.step(np.array(action))\n",
    "    \n",
    "    # Render\n",
    "    try:\n",
    "        # AsyncVectorEnv 대응: call(\"render\")로 모든 환경의 렌더링 결과를 리스트로 받음\n",
    "        frames_list = envs.call(\"render\")\n",
    "        # 첫 번째 환경(0번)의 영상만 저장\n",
    "        frames.append(frames_list[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Render failed at step {i}: {e}\")\n",
    "        break\n",
    "\n",
    "    if terminated.any() or truncated.any():\n",
    "        print(f\"Episode terminated at step {i}\")\n",
    "        break\n",
    "\n",
    "print(f\"Rollout complete. Frames caught: {len(frames)}\")\n",
    "\n",
    "if frames:\n",
    "    save_path = \"rollout.mp4\"\n",
    "    imageio.mimsave(save_path, frames, fps=30)\n",
    "    print(f\"Video saved to {save_path}\")\n",
    "else:\n",
    "    print(\"No frames captured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de866e75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyPendingCallError",
     "evalue": "Calling `reset_async` while waiting for a pending call to `call` to complete",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAlreadyPendingCallError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      9\u001b[39m MT10_TASKS = [\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreach-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpush-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpick-place-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdoor-open-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdrawer-close-v2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbutton-press-topdown-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpeg-insert-side-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwindow-open-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msweep-v2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbasketball-v2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m ]\n\u001b[32m     14\u001b[39m frames = []\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m obs, info = \u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting rollout...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 폰트 설정\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/site-packages/gymnasium/vector/async_vector_env.py:266\u001b[39m, in \u001b[36mAsyncVectorEnv.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    253\u001b[39m     *,\n\u001b[32m    254\u001b[39m     seed: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    255\u001b[39m     options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    256\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    257\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resets all sub-environments in parallel and return a batch of concatenated observations and info.\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m    259\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m        A batch of observations and info from the vectorized environment.\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reset_wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mw_render/lib/python3.12/site-packages/gymnasium/vector/async_vector_env.py:299\u001b[39m, in \u001b[36mAsyncVectorEnv.reset_async\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mlen\u001b[39m(seed) == \u001b[38;5;28mself\u001b[39m.num_envs\n\u001b[32m    296\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIf seeds are passed as a list the length must match num_envs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_envs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but got length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(seed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != AsyncState.DEFAULT:\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AlreadyPendingCallError(\n\u001b[32m    300\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling `reset_async` while waiting for a pending call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._state.value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` to complete\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    301\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._state.value),\n\u001b[32m    302\u001b[39m     )\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mreset_mask\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m options:\n\u001b[32m    305\u001b[39m     reset_mask = options.pop(\u001b[33m\"\u001b[39m\u001b[33mreset_mask\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAlreadyPendingCallError\u001b[39m: Calling `reset_async` while waiting for a pending call to `call` to complete"
     ]
    }
   ],
   "source": [
    "# Rollout and Render with Analytics (Success + Background)\n",
    "import imageio\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "\n",
    "frames = []\n",
    "obs, info = envs.reset()\n",
    "print(\"Starting rollout...\")\n",
    "\n",
    "# 폰트 설정\n",
    "try:\n",
    "    font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 12)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "for i in range(200):\n",
    "    # 1. Action & Q-value\n",
    "    action = agent.eval_action(obs)\n",
    "    current_q = agent.q_min(obs, np.array(action))[0]\n",
    "\n",
    "    # 2. Environment Step\n",
    "    next_obs, reward, terminated, truncated, info = envs.step(np.array(action))\n",
    "    \n",
    "    # 3. Target Q & TD Error\n",
    "    next_action_dist = agent.actor.apply_fn(agent.actor.params, next_obs)\n",
    "    next_action = next_action_dist.mode()\n",
    "    q_next_ens = agent.critic.apply_fn(agent.critic.target_params, next_obs, next_action)\n",
    "    min_q_next = jnp.min(q_next_ens, axis=0)\n",
    "    target_q = reward + (1 - terminated) * agent.gamma * min_q_next.flatten()\n",
    "    td_error = abs(float(target_q[0]) - current_q)\n",
    "\n",
    "    # 4. Task & Success Info\n",
    "    task_onehot = obs[0, -10:]\n",
    "    task_idx = int(np.argmax(task_onehot))\n",
    "    task_name = MT10_TASKS[task_idx] if task_idx < len(MT10_TASKS) else f\"Task {task_idx}\"\n",
    "    \n",
    "    # info[\"success\"]는 (num_envs,) 형태의 배열\n",
    "    is_success = bool(info[\"success\"][0]) if \"success\" in info else False\n",
    "    success_str = \"SUCCESS\" if is_success else \"FAIL\"\n",
    "\n",
    "    # 5. Render & Overlay\n",
    "    try:\n",
    "        frames_list = envs.call(\"render\")\n",
    "        frame_array = frames_list[0]\n",
    "        \n",
    "        img = Image.fromarray(frame_array)\n",
    "        draw = ImageDraw.Draw(img, \"RGBA\") # RGBA 모드로 그리기 (투명도 지원)\n",
    "        \n",
    "        # 텍스트 내용\n",
    "        text = (\n",
    "            f\"Task: {task_name}\\n\"\n",
    "            f\"Step: {i}\\n\"\n",
    "            f\"Q-value: {current_q:.2f}\\n\"\n",
    "            f\"TD-Error: {td_error:.4f}\\n\"\n",
    "            f\"Status: {success_str}\"\n",
    "        )\n",
    "        \n",
    "        # 텍스트 크기 계산하여 배경 박스 그리기\n",
    "        bbox = draw.textbbox((10, 10), text, font=font)\n",
    "        # 박스에 여백(padding) 좀 주고, 반투명 검은색(0,0,0,160)\n",
    "        draw.rectangle(\n",
    "            (bbox[0]-5, bbox[1]-5, bbox[2]+5, bbox[3]+5),\n",
    "            fill=(0, 0, 0, 160)\n",
    "        )\n",
    "        \n",
    "        # 텍스트 그리기 (흰색)\n",
    "        # 성공하면 녹색, 아니면 흰색 등으로 색상 변경 가능\n",
    "        text_color = (100, 255, 100) if is_success else (255, 255, 255)\n",
    "        draw.text((10, 10), text, font=font, fill=text_color)\n",
    "        \n",
    "        frames.append(np.array(img))\n",
    "    except Exception as e:\n",
    "        print(f\"Render failed at step {i}: {e}\")\n",
    "        break\n",
    "\n",
    "    if terminated.any() or truncated.any():\n",
    "        print(f\"Episode terminated at step {i}\")\n",
    "        break\n",
    "        \n",
    "    obs = next_obs\n",
    "\n",
    "print(f\"Rollout complete. Frames caught: {len(frames)}\")\n",
    "\n",
    "if frames:\n",
    "    save_path = \"rollout_overlay.gif\"\n",
    "    imageio.mimsave(save_path, frames, fps=30, loop=0)\n",
    "    print(f\"Video saved to {save_path}\")\n",
    "else:\n",
    "    print(\"No frames captured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a2bf056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeting Task 9: window-close-v2\n",
      "Target episode terminated at step 199\n",
      "Rollout complete. Frames caught: 200\n",
      "Video saved to rollout_task9-199990.gif\n"
     ]
    }
   ],
   "source": [
    "# Rollout and Render (Multi-env support)\n",
    "import imageio\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "# MuJoCo가 헤드리스 모드에서 GPU/EGL을 사용하도록 설정\n",
    "# 이 코드는 반드시 'import gymnasium'이나 'import mujoco' 보다 *먼저* 실행되어야 합니다!\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"EGL_LOG_LEVEL\"] = \"fatal\"\n",
    "# ✅ 원하는 태스크 번호 선택 (0~9)\n",
    "\n",
    "print(f\"Targeting Task {TARGET_TASK_IDX}: {MT10_TASKS[TARGET_TASK_IDX]}\")\n",
    "\n",
    "frames = []\n",
    "episode_return = 0.0  # 누적 보상 초기화\n",
    "\n",
    "obs, info = envs.reset()\n",
    "\n",
    "try:\n",
    "    font = ImageFont.truetype(\"DejaVuSans-Bold.ttf\", 12)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "for i in range(200):\n",
    "    # 1. Action (All 10 envs)\n",
    "    action = agent.eval_action(obs) # (10, action_dim)\n",
    "    \n",
    "    # Target의 Q-value만 계산 (Overlay용)\n",
    "    # obs[TARGET_TASK_IDX:TARGET_TASK_IDX+1] 형태로 슬라이싱해서 (1, dim)으로 전달\n",
    "    target_obs = obs[TARGET_TASK_IDX][None, ...] \n",
    "    target_action = np.array(action)[TARGET_TASK_IDX][None, ...]\n",
    "    current_q = agent.q_min(target_obs, target_action)[0]\n",
    "\n",
    "    r_val = float(reward[TARGET_TASK_IDX])\n",
    "    episode_return += r_val\n",
    "\n",
    "    # 2. Environment Step (All 10 envs)\n",
    "    next_obs, reward, terminated, truncated, info = envs.step(np.array(action))\n",
    "    \n",
    "    # 3. Target Q & TD Error (Only for target)\n",
    "    target_next_obs = next_obs[TARGET_TASK_IDX][None, ...]\n",
    "    \n",
    "    next_action_dist = agent.actor.apply_fn(agent.actor.params, target_next_obs)\n",
    "    next_act_mode = next_action_dist.mode()\n",
    "    q_next_ens = agent.critic.apply_fn(agent.critic.target_params, target_next_obs, next_act_mode)\n",
    "    min_q_next = jnp.min(q_next_ens, axis=0) # (1, 1) or (1,)\n",
    "    \n",
    "    # reward, term도 해당 인덱스 것만\n",
    "    r_val = float(reward[TARGET_TASK_IDX])\n",
    "    done_val = float(terminated[TARGET_TASK_IDX])\n",
    "    \n",
    "    target_q_val = r_val + (1 - done_val) * agent.gamma * float(min_q_next.flatten()[0])\n",
    "    td_error = abs(target_q_val - current_q)\n",
    "\n",
    "    # 4. Info\n",
    "    task_onehot = obs[TARGET_TASK_IDX, -10:]\n",
    "    task_idx_found = int(np.argmax(task_onehot))\n",
    "    task_name = MT10_TASKS[task_idx_found]\n",
    "    \n",
    "    success_flags = info[\"success\"] if \"success\" in info else [False]*10\n",
    "    is_success = bool(success_flags[TARGET_TASK_IDX])\n",
    "    success_str = \"SUCCESS\" if is_success else \"FAIL\"\n",
    "\n",
    "    # 5. Render (Target env only)\n",
    "    try:\n",
    "        # call(\"render\") returns list of 10 arrays\n",
    "        frames_list = envs.call(\"render\")\n",
    "        frame_array = frames_list[TARGET_TASK_IDX] # ✅ 원하는 것만 픽!\n",
    "        \n",
    "        img = Image.fromarray(frame_array)\n",
    "        draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "        \n",
    "        text = (\n",
    "            f\"Target: {MT10_TASKS[TARGET_TASK_IDX]}\\n\"\n",
    "            f\"Actual: {task_name} (idx {task_idx_found})\\n\"\n",
    "            f\"Reward: {r_val:.4f}\\n\"      # 이번 스텝 보상\n",
    "            f\"Return: {episode_return:.4f}\\n\" # 누적 보상\n",
    "            f\"Step: {i}\\n\"\n",
    "            f\"Q-value: {current_q:.2f}\\n\"\n",
    "            f\"TD-Error: {td_error:.4f}\\n\"\n",
    "            f\"Status: {success_str}\"\n",
    "        )\n",
    "        bbox = draw.textbbox((10, 10), text, font=font)\n",
    "        draw.rectangle((bbox[0]-5, bbox[1]-5, bbox[2]+5, bbox[3]+5), fill=(0, 0, 0, 160))\n",
    "        text_color = (100, 255, 100) if is_success else (255, 255, 255)\n",
    "        draw.text((10, 10), text, font=font, fill=text_color)\n",
    "        \n",
    "        frames.append(np.array(img))\n",
    "    except Exception as e:\n",
    "        print(f\"Render failed at step {i}: {e}\")\n",
    "        break\n",
    "\n",
    "    # 타겟 환경이 끝나면 종료 (선택사항)\n",
    "    if terminated[TARGET_TASK_IDX] or truncated[TARGET_TASK_IDX]:\n",
    "        print(f\"Target episode terminated at step {i}\")\n",
    "        break\n",
    "        \n",
    "    obs = next_obs\n",
    "\n",
    "print(f\"Rollout complete. Frames caught: {len(frames)}\")\n",
    "\n",
    "if frames:\n",
    "    save_path = f\"rollout_task{TARGET_TASK_IDX}-{STEP}.gif\"\n",
    "    imageio.mimsave(save_path, frames, fps=30, loop=0)\n",
    "    print(f\"Video saved to {save_path}\")\n",
    "else:\n",
    "    print(\"No frames captured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1749115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mw_render",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
